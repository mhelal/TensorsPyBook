{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e49fd61",
   "metadata": {},
   "source": [
    "# Ch3: Geometry & Algebra of Tensors\n",
    "    \n",
    "## 3.1 Motivation and Intuition\n",
    "\n",
    "A Video Analysis with Tensor Decomposition in Python example can be found at:\n",
    "https://towardsdatascience.com/video-analysis-with-tensor-decomposition-in-python-3a1fe088831c\n",
    "\n",
    "Other Examples are presented below, using a tensorisation step that is hand tailored to each examples, with attempts to generalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdea736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def tensorisation_Values (Df, components, value=\"value\", aggFunc=np.mean):\n",
    "    if components >= Df.shape[1]:\n",
    "        print (\"Number of components must be less or equal to number of the columns in the input matrix. Exiting without creating the tensor\")\n",
    "        return\n",
    "    minVals = []\n",
    "    maxVals = []\n",
    "    tensorShape = []\n",
    "    for i in range(components):\n",
    "        minVal = Df.iloc[:,i].min()\n",
    "        # this will be an index, therefore starting from zero is necessary\n",
    "        if minVal > 0:\n",
    "            Df.iloc[:,i] += minVal\n",
    "            minVal = 0\n",
    "        if minVal < 0:\n",
    "            Df.iloc[:,i] -= minVal\n",
    "            minVal = 0\n",
    "        minVals.append(minVal)\n",
    "        # also the max value need to be positive non-zero, because it will be the tensor shape \n",
    "        maxVal = Df.iloc[:,i].max()\n",
    "        if maxVal <= 0:\n",
    "            Df.iloc[:,i] -= maxVal + 1\n",
    "            maxVal = 1\n",
    "        maxVals.append(maxVal)\n",
    "        print(\"mode  \" + str(i) + \" max value =\" + str(maxVal) + \", min value = \" + str(minVal))\n",
    "        tensorShape.append(int(maxVal)+1)\n",
    "\n",
    "    # update the values in the array, to be used as indices\n",
    "    for k,j in Df.iterrows():\n",
    "            for i in range(components):\n",
    "                j[i] = int(math.floor(j[i])) + abs(int(minVals[i])) + 1\n",
    "    print (tensorShape)\n",
    "    tensorShape = tuple(tensorShape) \n",
    "    tensor_array = np.zeros(tensorShape)\n",
    "    count = 0\n",
    "    for k,j in Df.iterrows():\n",
    "        count = count + 1\n",
    "        t_index = tuple(\n",
    "            int(j[i]) for i in range(components)\n",
    "        )\n",
    "        #print (t_index)\n",
    "        tensor_array[t_index] = aggFunc(j[value])\n",
    "\n",
    "    return tensor_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbd81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "\n",
    "userdata = pd.read_csv('data/GlobalLandTemperaturesByMajorCity.csv')\n",
    "columns = ['dt','AverageTemperature','AverageTemperatureUncertainty','City','Country','Latitude','Longitude'] # such that these will be x\n",
    "df=userdata[columns].copy()\n",
    "Values = userdata[\"AverageTemperature\"] # this will be the values of the tensor\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ead59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will tensorise in the same order mentioned in chapter 3 first section on motivational problem\n",
    "# First example is one temperature value as a scalar (rank-zero tensor), which does not require tensorisation, just indexing will do\n",
    "df.iloc[0, 1] # specifying the index values, which is not usually interpreted easily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['City']== 'Abidjan') & (df['dt']=='1849-01-01') ,['AverageTemperature']] # specifing the values needed (city and date values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67223653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second example is all temperature values in this dataset or in a specific city as a vector (rank-one tensor), which does not require tensorisation, just indexing will do\n",
    "\n",
    "df.loc[df['City'] == 'Abidjan']['AverageTemperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third example is temperature values per city (rank-two tensor). We will do it using pivot tables, and again with tensorisation\n",
    "# pivot tables are another method in handling multi-way analysis\n",
    "# checking how many cardiac cases in each age value\n",
    "\n",
    "cityTempMeans = df.pivot_table(values='AverageTemperature',\n",
    "                               index='City', \n",
    "                               aggfunc=np.mean,               ## aggfunc='size', # size if you want to aggregate by frequency counting\n",
    "                               fill_value=0)\n",
    "cityTempMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ccd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "cityTempMeans.iloc[0,0] # Average temperature for Abidjan by indexing the pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['City'] == 'Abidjan']['AverageTemperature'].mean() # getting to the same value from the original dataset DataFrame, probably the mean function used here is not np.mean since the value is slightly different, but could be rounding error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac54ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    print(sdf.iloc[:,i].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e55177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorising by arranging the columns as coordinates first, and last column is the value to aggregate on\n",
    "\n",
    "columns = ['City','AverageTemperature'] # such that these will be x\n",
    "sdf=userdata[columns].copy()\n",
    "\n",
    "# we need to encode all coordinate columns numerically\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# lbl_encoder object knows how to understand word labels.\n",
    "city_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "sdf['CityBasis']= city_encoder.fit_transform(sdf['City'])\n",
    "sdf['CityBasis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f34614",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca6fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_encoder.inverse_transform([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_encoder.transform(['Abidjan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462c78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['CityBasis', 'City','AverageTemperature'] # such that these will be x\n",
    "sdf=sdf[columns].copy()\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "\n",
    "tensor_array = tensorisation_Values (sdf, 1, value=\"AverageTemperature\", aggFunc=np.mean)\n",
    "tensor2 = tl.tensor(tensor_array)\n",
    "tensor2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafafc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2 # the tensorisation function can also be updated to handle nan values, and to be vectorised and optimisaed for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth example is temperature values per location as Latitude & Longitude  (rank-three tensor). \n",
    "#Attemping pivot tables, will still be rank-two, as we create a matrix with the both location columns flattened in one mode\n",
    "columns = ['dt','AverageTemperature','AverageTemperatureUncertainty','City','Country','Latitude','Longitude'] # such that these will be x\n",
    "\n",
    "\n",
    "locTempMeans = df.pivot_table(values='AverageTemperature',\n",
    "                               index=['Latitude','Longitude'], \n",
    "                               aggfunc=np.mean,               ## aggfunc='size', # size if you want to aggregate by frequency counting\n",
    "                               fill_value=0)\n",
    "locTempMeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cdd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will do it using tensorisation\n",
    "\n",
    "columns = ['Latitude','Longitude','AverageTemperature'] \n",
    "sdf=userdata[columns].copy()\n",
    "\n",
    "sdf # 'Latitude','Longitude' contain numeric values followed by N/S in the first, and E/W in the second, which is degree minute second (DMS) coordinates \n",
    "# We will need to be numerically encode them to be turned to coordinate basis using decimal degrees\n",
    "# there is a solution here https://medium.com/@quinn.dougherty92/simple-geographical-encoding-8293fde9e964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9067179",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dms2dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b708241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geopandas has interesting solutions, but will use dms2dec for simplicity\n",
    "from dms2dec.dms_convert import dms2dec\n",
    "sdf['Latitude'] = sdf['Latitude'].apply(dms2dec)\n",
    "sdf['Longitude'] = sdf['Longitude'].apply(dms2dec)\n",
    "sdf['Latitude'] = sdf['Latitude'].astype(float)\n",
    "sdf['Longitude'] = sdf['Longitude'].astype(float)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191567bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need to update the tensorisation function to be able to aggregate by mean or other function, and take\n",
    "# the values as mean of rows returned from a condition per column in the dataframe\n",
    "# this is almost tailored to Latitude & Longitude specific values, it is better to be updated to ranges, such that\n",
    "# values are aggregated when they are >= the current basis index and < next basis index\n",
    "# many optimisations can be achived for vectorisation, paralleisation, quantisation\n",
    "def tensorisation2_Values (Df, components, value=\"value\", aggFunc=np.mean):\n",
    "    if components >= Df.shape[1]:\n",
    "        print (\"Number of components must be less or equal to number of the columns in the input matrix. Exiting without creating the tensor\")\n",
    "        return\n",
    "    minVals = []\n",
    "    maxVals = []\n",
    "    tensorShape = []\n",
    "    for i in range(components):\n",
    "        minVal = Df.iloc[:,i].min()\n",
    "        # this will be an index, therefore starting from zero is necessary\n",
    "        if minVal > 0:\n",
    "            Df.iloc[:,i] += minVal\n",
    "            minVal = 0\n",
    "        if minVal < 0:\n",
    "            Df.iloc[:,i] -= minVal\n",
    "            minVal = 0\n",
    "        minVals.append(minVal)\n",
    "        # also the max value need to be positive non-zero, because it will be the tensor shape \n",
    "        maxVal = Df.iloc[:,i].max()\n",
    "        if maxVal <= 0:\n",
    "            Df.iloc[:,i] -= maxVal + 1\n",
    "            maxVal = 1\n",
    "        maxVals.append(maxVal)\n",
    "        print(\"mode  \" + str(i) + \" max value =\" + str(maxVal) + \", min value = \" + str(minVal))\n",
    "        tensorShape.append(int(maxVal)+1)\n",
    "\n",
    "    # update the values in the array, to be used as indices\n",
    "    for k,j in Df.iterrows():\n",
    "            for i in range(components):\n",
    "                j[i] = int(math.floor(j[i])) + abs(int(minVals[i])) + 1\n",
    "    print (tensorShape)\n",
    "    tensorShape = tuple(tensorShape) \n",
    "    tensor_array = np.zeros(tensorShape)\n",
    "    \n",
    "    ## two useful functions\n",
    "    np.unravel_index(0, tensorShape) # flat linear index to multidimensional index \n",
    "    np.ravel_multi_index([tensorShape[i]-1 for i in range(len(tensorShape))], tensorShape) # multidimensional index to flat linear index\n",
    "\n",
    "    for i in range (np.prod(tensorShape)-1): # iterate through the tensor flat indices, can try for element in np.nditer(arr): then get the index of the element\n",
    "        t_index = np.unravel_index(i, tensorShape) # get the tensor multidimensional index\n",
    "        print (\"i: \" + str(i) + \" t_in: \" + str(t_index))\n",
    "        condition = '' # accumulate the conditions to add to the data frame selection\n",
    "        for j in range(len(t_index)):       # iterate through the dataframe columns\n",
    "            if j==0:\n",
    "                condition += '(Df[Df.columns[' + str(j)+']] == ' + str(t_index[j]) + ')'\n",
    "            else:\n",
    "                condition += ' & (Df[Df.columns[' + str(j)+']]  == ' + str(t_index[j]) + ')'\n",
    "            print (\"j: \" + str(j) + \" column: \" + Df.columns[j] + \" cond: \" + condition)\n",
    "            \n",
    "        #print (\"Condition is: \" + condition)\n",
    "        if len(condition) > 0:    \n",
    "            #print (eval(condition))\n",
    "            tensor_array[t_index] = aggFunc(Df.loc[eval(condition)]['AverageTemperature'])\n",
    "        else:\n",
    "            tensor_array[t_index] = aggFunc(Df.loc['AverageTemperature'])\n",
    "\n",
    "\n",
    "    return tensor_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca50ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_array =  tensorisation2_Values (sdf, 2, value=\"AverageTemperature\", aggFunc=np.mean)\n",
    "tensor2 = tl.tensor(tensor_array)\n",
    "tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifth example is temperature values per location as Latitude & Longitude & date  (rank-four tensor). We will do it using tensorisation\n",
    "#Attemping pivot tables, will still be rank-two, as we create a matrix with the both location columns and time column flattened in one mode\n",
    "columns = ['dt','AverageTemperature','AverageTemperatureUncertainty','City','Country','Latitude','Longitude'] # such that these will be x\n",
    "\n",
    "\n",
    "locTempMeans = df.pivot_table(values='AverageTemperature',\n",
    "                               index=['Latitude','Longitude','dt'], \n",
    "                               aggfunc=np.mean,               ## aggfunc='size', # size if you want to aggregate by frequency counting\n",
    "                               fill_value=0)\n",
    "locTempMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will do it using tensorisation\n",
    "\n",
    "columns = ['Latitude','Longitude','dt', 'AverageTemperature'] \n",
    "sdf=userdata[columns].copy()\n",
    "\n",
    "sdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have here a date column, we can create time series by lagging function and quantisation of values, but will simply encode here\n",
    "date = pd.to_datetime(sdf['dt'])\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c979178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf['Latitude'] = sdf['Latitude'].apply(dms2dec)\n",
    "sdf['Longitude'] = sdf['Longitude'].apply(dms2dec)\n",
    "sdf['Latitude'] = sdf['Latitude'].astype(float)\n",
    "sdf['Longitude'] = sdf['Longitude'].astype(float)\n",
    "\n",
    "date_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "sdf['dtBasis']= date_encoder.fit_transform(pd.to_datetime(sdf['dt']))\n",
    "sdf['dtBasis'] = sdf['dtBasis'].astype(float)\n",
    "sdf['dtBasis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35495cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Latitude','Longitude','dtBasis', 'AverageTemperature'] \n",
    "sdf=sdf[columns].copy()\n",
    "\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc74e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_array =  tensorisation2_Values (sdf, 3, value=\"AverageTemperature\", aggFunc=np.mean)\n",
    "tensor2 = tl.tensor(tensor_array)\n",
    "tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13491ebe",
   "metadata": {},
   "source": [
    "## We will consider another problem using Data already in tensor form.\n",
    "\n",
    "\n",
    "The data set is from http://www.models.life.ku.dk/nwaydata\n",
    "in Matlab form, and can be read by scipy loadmat function, and saved as numpy arrays for easier loads later\n",
    "\n",
    "The data has X variable as 3-way tensor of  5 samples in mode - 1 (rows) 5 × 51 × 201. , containing different amounts of tyrosine, tryptophan and phenylalanine amino acids belong to three amino acids dissolved in phosphate buffered water. The samples were measured by fluorescence (excitation 250-300 nm, emission 250-450 nm, 1 nm intervals) on a spectrofluorometer \n",
    "\n",
    "The data has Y variable, which is the ground truth,  the known concentrations of the three chemicals (mode-2) that are in the samples (mode-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "amino = scipy.io.loadmat('data/amino.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = amino.get('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5922a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = amino.get('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('data/amino_x', X)\n",
    "np.save('data/amino_y', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f58eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab25753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a1337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing Parafac decomposition\n",
    "from tensorly.decomposition import parafac\n",
    "weights, factors = parafac(X,rank = 3, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466780dc",
   "metadata": {},
   "source": [
    "## PARAFAC should have three components and therefore a 5 × 3 so called score matrix (first mode loading matrix). Each column in this score matrix should approximately match the concentration of one of the three aminoacids which are held in the 5 × 3 Y matrix. Matching in this case, means that the corresponding columns should be correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7feff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.shape for f in factors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ceb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(Y, factors[0]) # obviously they are not close enough for numpy, will do all possible column permutations correlation then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def corrEstimate (i, j, Y, factors):\n",
    "    data = {\n",
    "        'Y': Y[:,i], \n",
    "        'Y_p': factors[0][:,j]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Y', 'Y_p'])\n",
    "    corr = df.corr()\n",
    "    print(\"Correlation matrix of estimated column\" + str(i) + \" with ground truth \" + str(j) + \" is : \")\n",
    "    print(corr)\n",
    "    \n",
    "    return corr, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e876bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "ax = 0\n",
    "corrList = []\n",
    "for i in range(Y.shape[1]):\n",
    "    for j in range(factors[0].shape[1]):\n",
    "        corr, ax = corrEstimate(i, j, Y, factors)\n",
    "        corrList.append(corr)\n",
    "\n",
    "n=0 # there is a bug that makes the plot read the same correlation matrix every time, I tried inside the function, and then added the list to separate the variables, and not good\n",
    "for i in range(Y.shape[1]):\n",
    "    for j in range(factors[0].shape[1]):\n",
    "        ax = plt.subplot(3, 3, n+1)\n",
    "        plt.imshow(corrList[n],cmap='coolwarm',interpolation='nearest')\n",
    "        n= n+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef678b3",
   "metadata": {},
   "source": [
    "### It is obvious that the first estimated chemical matches the first ground truth, more than the other two\n",
    "\n",
    "### The second estimated chemical matches the third ground truth, \n",
    "\n",
    "### The third estimated checmical matches the second ground truth\n",
    "\n",
    "### The second and third are swapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1cd04",
   "metadata": {},
   "source": [
    "# Ch6: Fundamentals of Tensor Analysis & Applications\n",
    "\n",
    "## 6.1 Scientific Computing Applications\n",
    "\n",
    "## Second Problem is a survey answers about happiness scores related to 3 conditions. This created a three-way contingency table has as its variables: Happiness reported by participants in a survey (i mode-1 : 3 categories), Number of siblings (j mode-2 : Siblings - 5 categories) and the Years of schooling completed (k mode-3 : Schooling - 4 categories). It is thus a frequency table containing in the cells the number of people with a particular combination of categories. \n",
    "\n",
    "## the data is stored in a dat file that reads a 2 dimensional matricised tensor, (12, 5), assuming that reshaping into (3, 4, 5) and swapping the mode-2 and mode-3 in the problem definition in https://three-mode.leidenuniv.nl/ will be ok\n",
    "\n",
    "## Will decompose with Tucker to find which rank gives the best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# read flash.dat to a list of lists\n",
    "datContent = [i.strip().split() for i in open(\"data/Happiness.dat\").readlines()]\n",
    "\n",
    "X = np.array(datContent)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(3, 4, 5)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing Tucker decomposition\n",
    "from tensorly.decomposition import tucker\n",
    "import tensorly as tl\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def doTucker (X, rank):\n",
    "    X = tl.tensor(X,dtype=float)\n",
    "    core, factors = tucker(X, rank=rank)\n",
    "    tucker_reconstruction_2 = tl.tucker_to_tensor((core, factors))\n",
    "\n",
    "    tk_RMSE = math.sqrt(np.square(np.subtract(X,tucker_reconstruction_2)).mean() )\n",
    "    print (\"Tucker \" + str(rank) + \" RMSE = \", tk_RMSE)\n",
    "    return core ,factors, tk_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d0d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing Tucker decomposition\n",
    "from tensorly.decomposition import tucker\n",
    "import tensorly as tl\n",
    "\n",
    "ranks = []\n",
    "tucker_RMSE=[]\n",
    "\n",
    "for i in range(np.prod(X.shape)): # iterate through the flat index\n",
    "    rank= np.unravel_index(i, X.shape) # get the multidimensional index to use as a rank, in case it does not contain a zero, this will traverse all possible ranks\n",
    "    if np.all(rank):\n",
    "        core ,factors, tk_RMSE = doTucker(X, rank)\n",
    "        tucker_RMSE.append(tk_RMSE)\n",
    "        ranks.append(str(rank))\n",
    "\n",
    "\n",
    "max = np.argmin(tucker_RMSE)\n",
    "print (\"Lowest RMSE achieched at rank = \" + ranks[max]) # this will show the full matrix rank, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure( figsize=(20,6))\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(ranks)]\n",
    "\n",
    "plt.bar(ranks, tucker_RMSE, color='green')\n",
    "plt.xlabel(\"Dimensionality Reduction Methods\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Comparing Classification RMSE using RandomForest on Linear unsupervised PCA, supervised LDA/QDA and various Embedding Learning Algorithms\")\n",
    "\n",
    "plt.xticks(x_pos, ranks)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e00df7d",
   "metadata": {},
   "source": [
    "## Looking at all possible ranks reconstruction error, it seems the highest errors occured when all modes were reduced, but when first mode only was reduced, the error was small, which means it is not very dominant in this dataset, and the third mode seems to be the most dominant.  \n",
    "\n",
    "In the book ( Kroonenberg, P.M., 2008. Applied multi-way data analysis, Wiley series in probability and statistics. Wiley-Interscience, Hoboken, N.J.) the author showed that rank (2,2,2) was the most fit to this dataset, which is proven here as well. The software he used can be downloaded from https://three-mode.leidenuniv.nl/ , "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f3d9f",
   "metadata": {},
   "source": [
    "### Tensorlab (Matlab package) Tensorisation Functions:\n",
    "\n",
    "##### A 2-dimensional implementation is available in scipy package that is not based on tensor higher dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dccefde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5],\n",
       "       [2, 3, 4, 5, 0],\n",
       "       [3, 4, 5, 0, 0],\n",
       "       [4, 5, 0, 0, 0],\n",
       "       [5, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import hankel\n",
    "\n",
    "\n",
    "v = [1, 2, 3, 4, 5]\n",
    "V = hankel(v);\n",
    "V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a95cdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 5, 4, 3, 2, 2, 1, 5, 4, 3, 3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4,\n",
       "        3, 2, 1],\n",
       "       [5, 4, 3, 2, 2, 1, 5, 4, 3, 3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3,\n",
       "        2, 1, 0],\n",
       "       [4, 3, 2, 2, 1, 5, 4, 3, 3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2,\n",
       "        1, 0, 0],\n",
       "       [3, 2, 2, 1, 5, 4, 3, 3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1,\n",
       "        0, 0, 0],\n",
       "       [2, 2, 1, 5, 4, 3, 3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0,\n",
       "        0, 0, 0],\n",
       "       [2, 1, 5, 4, 3, 3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [1, 5, 4, 3, 3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [5, 4, 3, 3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [4, 3, 3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [3, 3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [3, 2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [2, 1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [1, 5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [5, 4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [4, 4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [4, 3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [3, 2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [2, 1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [1, 5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [5, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = hankel(V);\n",
    "V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b51d7ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7da711d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 5, 4, ..., 0, 0, 0],\n",
       "       [5, 4, 3, ..., 0, 0, 0],\n",
       "       [4, 3, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = hankel(V);\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51e7a86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625, 625)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58872fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5],\n",
       "       [2, 1, 2, 3, 4],\n",
       "       [3, 2, 1, 2, 3],\n",
       "       [4, 3, 2, 1, 2],\n",
       "       [5, 4, 3, 2, 1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import toeplitz\n",
    "V = toeplitz(v);\n",
    "V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4e3097e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 5, 4, 3, 2],\n",
       "       [2, 1, 5, 4, 3],\n",
       "       [3, 2, 1, 5, 4],\n",
       "       [4, 3, 2, 1, 5],\n",
       "       [5, 4, 3, 2, 1]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import circulant\n",
    "V = circulant(v);\n",
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6396dec",
   "metadata": {},
   "source": [
    "### Attempting to implement in higher dimensions it as explained in https://www.tensorlab.net/doc/tensorization.html#hankelization-sec  and https://core.ac.uk/download/pdf/34637588.pdf \n",
    "\n",
    "\n",
    "##### Hankelization : Will lead to curse of dimensionality, and reduced forms are performed by tensor factorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d93619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def hankelize (v, order = 2, sizes = None , indices = None,Dim = 1 ):\n",
    "    N = len(v)\n",
    "    if order > N:\n",
    "        print ('The order should not be larger than the number of elements in the tensorized dimension!')\n",
    "        return\n",
    "    if order < 2:\n",
    "        print ('The order must be larger than or equal to 2!')\n",
    "        return\n",
    "    if order == 2:\n",
    "        if sizes == None:\n",
    "            I = int(math.ceil(N / 2))\n",
    "            J = N - I + 1\n",
    "        else:\n",
    "            I = sizes[0]\n",
    "            J = sizes[1]\n",
    "        H = np.ndarray(shape=(I,J), dtype=np.int8)\n",
    "        for i in range (0, I):\n",
    "            for j in range (0, J):\n",
    "                H[i, j] = v[i+j-1]\n",
    "    else:\n",
    "            # ceil((1:options.Order-1)*N/options.Order);\n",
    "            I = np.ndarray(shape=(order), dtype=np.int8) # resulting tensorShape\n",
    "            # Y(ceil((k-1)*N/K):               ceil(k*N/K))  segments\n",
    "            elements = 0\n",
    "            for i in range (0, order):\n",
    "                if sizes == None:\n",
    "                    if i < order - 1:\n",
    "                        I[i] = int(math.ceil(N / order))\n",
    "                        #I[i] = int((N+order) / order) + 1\n",
    "                        elements += I[i]\n",
    "                    else:\n",
    "                        I[i]  = N - order + 1\n",
    "                        #I[i] = N +order - elements\n",
    "                else:\n",
    "                    I[i] = sizes[i]\n",
    "            tensorshape = tuple(I)\n",
    "            print (tensorshape)\n",
    "            H = np.ndarray(shape=tensorshape, dtype=np.int8)\n",
    "            \n",
    "            # This method of iterating through the high dimensional space in one-level non-nested and hard coded for every order like the above 2-D example\n",
    "            # might be the reason the order of the elements are not as described in the references. However the diagonal, anti-diagonal, or skew diagonal \n",
    "            # properties seem to be preserved. Further testing might be needed to maintain that a Hankel tensor has constant anti-hyperplanes, and take\n",
    "            # care of all exception handling, like mismatching order or parameter values or too large tensor to create a smaller one.\n",
    "            \n",
    "            for i in range (np.prod(I)): # iterate through the tensor flat indices\n",
    "                t_index = np.unravel_index(i, I) # get the tensor multidimensional index\n",
    "                print (t_index)\n",
    "                H[t_index] =v[np.sum(t_index) - order + 1]\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4173f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 1, 2],\n",
       "       [1, 2, 3],\n",
       "       [2, 3, 4]], dtype=int8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v = [1, 2, 3, 4, 5]\n",
    "V = hankelize(v);\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5752dbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[4, 5, 1],\n",
       "        [5, 1, 2]],\n",
       "\n",
       "       [[5, 1, 2],\n",
       "        [1, 2, 3]]], dtype=int8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = hankelize(v, order=3);\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58006aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5],\n",
       "       [5, 1]], dtype=int8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a52e522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 1],\n",
       "       [1, 2]], dtype=int8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c37186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [2, 3]], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828fbe8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 5, 1],\n",
       "        [5, 1, 2]],\n",
       "\n",
       "       [[5, 1, 2],\n",
       "        [1, 2, 3]]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eebf098d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe79aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 5)\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 0, 3)\n",
      "(0, 0, 4)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 1, 3)\n",
      "(0, 1, 4)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(0, 2, 3)\n",
      "(0, 2, 4)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 0, 3)\n",
      "(1, 0, 4)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 1, 3)\n",
      "(1, 1, 4)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(1, 2, 3)\n",
      "(1, 2, 4)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 0, 3)\n",
      "(2, 0, 4)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 1, 3)\n",
      "(2, 1, 4)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "(2, 2, 3)\n",
      "(2, 2, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[6, 7, 1, 2, 3],\n",
       "        [7, 1, 2, 3, 4],\n",
       "        [1, 2, 3, 4, 5]],\n",
       "\n",
       "       [[7, 1, 2, 3, 4],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [2, 3, 4, 5, 6]],\n",
       "\n",
       "       [[1, 2, 3, 4, 5],\n",
       "        [2, 3, 4, 5, 6],\n",
       "        [3, 4, 5, 6, 7]]], dtype=int8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = [1, 2, 3, 4, 5, 6, 7]\n",
    "V = hankelize(v, order=3);\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d59fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7, 1],\n",
       "       [7, 1, 2],\n",
       "       [1, 2, 3]], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c499a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 1, 2],\n",
       "       [1, 2, 3],\n",
       "       [2, 3, 4]], dtype=int8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aec00fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 1, 2, 3, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2,\n",
       "       3, 4, 5, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 2, 3, 4, 5, 6, 3, 4, 5, 6,\n",
       "       7], dtype=int8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorly as tl\n",
    "\n",
    "v_recon = tl.tensor_to_vec( tl.unfold(V, 0))\n",
    "v_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "179566f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "\n",
    "    \n",
    "def hankelize(X, **kwargs):\n",
    "    defaultKwargs = { 'Order': 2,\n",
    "        'Dim': 1,\n",
    "        'Sizes': np.NaN,\n",
    "        'Ind': np.NaN,\n",
    "        'PermToFirst': False,\n",
    "        'Full': 'auto',\n",
    "        'FullLimit': 1}\n",
    "    order = kwargs.get('Order', 2)\n",
    "    dim = kwargs.get('Dim', 1)\n",
    "    sizes = kwargs.get('Sizes', np.NaN)\n",
    "    ind = kwargs.get('Ind', np.NaN)\n",
    "    perm_to_first = kwargs.get('PermToFirst', False)\n",
    "    full = kwargs.get('Full', 'auto')\n",
    "    full_limit = kwargs.get('FullLimit', 1)\n",
    "    \n",
    "    args = {'Order': order,\n",
    "        'Dim': dim,\n",
    "        'Sizes': sizes,\n",
    "        'Ind': ind,\n",
    "        'PermToFirst': perm_to_first,\n",
    "        'Full': full,\n",
    "        'FullLimit': full_limit}\n",
    "    KeepUnmatched = False\n",
    "    isdefault =  args ==defaultKwargs\n",
    "    shared_items = {k: args[k] for k in args if k in defaultKwargs and args[k] == defaultKwargs[k]}\n",
    "    \n",
    "    if dim > np.ndim(X):\n",
    "        raise ValueError('The given dimension is too large!')\n",
    "    if dim == 2 and np.ndim(X) == 1:\n",
    "        X = np.reshape(X, (-1, 1)) # Row to column vector: reshape(-1, 1) \n",
    "        \n",
    "        \n",
    "    sx = np.shape(X)\n",
    "    N = sx[dim-1]\n",
    "    size_other = sx[dim:]  # list(sx[:dim-1]) + list(sx[dim:])\n",
    "    \n",
    "    if size_other == [1]:\n",
    "        size_other = []\n",
    "    \n",
    "    # Matricize the data\n",
    "    if np.ndim(X) == 2:\n",
    "        if dim == 2:\n",
    "            Xmat = X.transpose()\n",
    "        else:\n",
    "            Xmat = X\n",
    "    else:\n",
    "        Xmat = tl.unfold(X, dim-1)\n",
    "    Xmat.squeeze()\n",
    "    print (\"input shape: \" , Xmat.shape)\n",
    "        \n",
    "    if order < 2:\n",
    "        raise ValueError('The order must be larger than or equal to 2!')\n",
    "    \n",
    "    #  Set PermToFirst \n",
    "    if perm_to_first == False:\n",
    "        perm_to_first = False\n",
    "    \n",
    "    if not isinstance(perm_to_first, bool):\n",
    "        raise ValueError('The option PermToFirst should be a boolean!')\n",
    "        \n",
    "    \n",
    "    if perm_to_first: \n",
    "        perm_to_first = 1;\n",
    "    else: \n",
    "        perm_to_first = dim;\n",
    "   \n",
    "    # Set the default values\n",
    "    if order == 2:\n",
    "        if np.all(np.isnan(ind)):\n",
    "            if np.all(np.isnan(sizes)):\n",
    "                ind = np.ceil(np.arange(1, order) * N / order)\n",
    "                ind = ind.astype(np.int64)\n",
    "                print (\"Order: \" , order)\n",
    "                print (\"ind: \" , ind)\n",
    "            else:\n",
    "                order = len(sizes)+1\n",
    "                print (\"Order: \" , order)\n",
    "                print (\"ind: \" , ind)\n",
    "                print (\"sizes: \" , sizes)\n",
    "\n",
    "                ind = np.cumsum(sizes) - np.arange(0, order-1)\n",
    "        else:\n",
    "            order = len(ind) \n",
    "            if np.all(not np.isnan(sizes)) and (len(ind) != len(sizes) or not np.all(ind == np.cumsum(sizes) - np.arange(0, order-1))):\n",
    "                raise ValueError('The option fields Ind and Sizes do not correspond!')\n",
    "\n",
    "        if order != len(ind)+1:\n",
    "            raise ValueError('The number of indices should be equal to order-1!')\n",
    "    else:\n",
    "        if np.all(np.isnan(ind)):\n",
    "            if np.all(np.isnan(sizes)):\n",
    "                ind = np.ceil(np.arange(1, order) * N / order)\n",
    "                ind = ind.astype(np.int64)\n",
    "            else:\n",
    "                if len(sizes)!=order:\n",
    "                    raise ValueError('The number of sizes should be equal to order-1')\n",
    "                ind = np.cumsum(sizes) - np.arange(0, order-1)\n",
    "        else:\n",
    "            if np.all(not np.isnan(sizes)) and (len(ind)!=len(sizes) or\n",
    "                    np.any(ind!=np.cumsum(sizes)-np.arange(0, order-1))):\n",
    "                raise ValueError('The option fields ind and sizes do not correspond!')\n",
    "    \n",
    "    if(order!=len(ind)+1):\n",
    "        raise ValueError('The number of indices should be equal to order-1!')\n",
    "    print (\"N: \" , N)\n",
    "    print (\"Dim: \" , dim)\n",
    "    print (\"Order: \" , order)\n",
    "    print (\"ind: \" , ind)\n",
    "    print (\"sizes: \" , sizes)\n",
    "    print (\"perm_to_first: \" , perm_to_first)\n",
    "    print (\"size_other: \" , size_other)\n",
    "               \n",
    "    # Determine the size of the Hankel matrices/tensors\n",
    "    #size_hankel = np.array([ind, N]) - np.array([0] + list(ind[:-1]))\n",
    "    xx = np.hstack((ind, N))\n",
    "    yy = np.hstack(([0], np.subtract(ind, 1)))\n",
    "    size_hankel = np.subtract(xx, yy)\n",
    "    print (\"size_hankel: \" , size_hankel)\n",
    "    \n",
    "    if np.any(size_hankel < 0):\n",
    "        raise ValueError('The indices should increase monotonically between 0 and N!')\n",
    "        \n",
    "    if order > N:\n",
    "        raise ValueError('The order should not be larger than the number of elements in the tensorized dimension!')  \n",
    "    whosX = X.nbytes / X.shape[dim-1] * np.prod(size_hankel)\n",
    "    totalbytes = whosX\n",
    "    print (\"Total required Bytes are: \" , totalbytes)\n",
    "    if full == 'auto':\n",
    "        if totalbytes > full_limit * 2**30:\n",
    "            full = False\n",
    "            print('The fullLimit has been reached, and instead of the dense tensor, the efficient representation is returned. The dense tensor can be obtained by setting the \"full\" option to True.')\n",
    "        else:\n",
    "            full = True\n",
    "    \n",
    "    t = order+ np.arange(1,perm_to_first)           \n",
    "    repermorder = np.hstack(\n",
    "        (order+ np.arange(1,perm_to_first), np.arange(1, order), np.arange(order+perm_to_first-1,len(np.hstack((size_hankel,size_other)))+1)))\n",
    "    #print (\"repermorder: \", repermorder)\n",
    "    hstruct = None\n",
    "    xx = np.hstack((size_hankel,size_other))\n",
    "    yy = np.squeeze(np.ones((1 , len(repermorder) - len(np.hstack((size_hankel, size_other)))+1)))\n",
    "    structSize = np.hstack((xx, yy))\n",
    "    if (full is True) or (hstruct is not None):\n",
    "        hstruct = {\n",
    "            'type': 'hankel',\n",
    "            'val': Xmat,\n",
    "            'dim': dim,\n",
    "            'order': order,\n",
    "            'ind': ind,\n",
    "            'ispermuted': perm_to_first != dim,\n",
    "            'repermorder': repermorder,\n",
    "            'size': structSize,\n",
    "            'size' : structSize[repermorder],\n",
    "            'subsize': {\n",
    "                'hankel': size_hankel,\n",
    "                'other': size_other\n",
    "            }\n",
    "        }\n",
    "    print (\"hstruct\", hstruct)    \n",
    "    if full is True:\n",
    "        allind2 = subhankel(size_hankel)\n",
    "        H = Xmat[allind2, :]\n",
    "        xx = np.hstack((size_hankel, size_other))\n",
    "        xx = xx.astype(np.int64)\n",
    "        H = H.reshape(xx)\n",
    "        if perm_to_first != 1:\n",
    "            H = np.transpose(H, axes=repermorder)\n",
    "    else:\n",
    "        H = hstruct\n",
    "        \n",
    "    return H\n",
    "\n",
    "def subhankel(sizes):\n",
    "    lidx = np.transpose(np.arange(1, sizes[0]+1))\n",
    "    for i in range(1, len(sizes)):\n",
    "        ridx = np.arange(0, sizes[i])\n",
    "        xx = np.squeeze(np.hstack(( np.ones(( i+1)) , len(ridx))))\n",
    "        xx = xx.astype(np.int64)\n",
    "        ridx = ridx.reshape(xx)\n",
    "        lidx =  np.add.outer(lidx, ridx)\n",
    "        \n",
    "    allind = list(lidx.flatten())\n",
    "    allind = np.subtract(allind, 1)\n",
    "    return allind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2398b1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (5, 1)\n",
      "Order:  2\n",
      "ind:  [3]\n",
      "N:  5\n",
      "Dim:  1\n",
      "Order:  2\n",
      "ind:  [3]\n",
      "sizes:  nan\n",
      "perm_to_first:  1\n",
      "size_other:  ()\n",
      "size_hankel:  [3 3]\n",
      "Total required Bytes are:  36.0\n",
      "hstruct {'type': 'hankel', 'val': array([[1],\n",
      "       [2],\n",
      "       [3],\n",
      "       [4],\n",
      "       [5]]), 'dim': 1, 'order': 2, 'ind': array([3], dtype=int64), 'ispermuted': False, 'repermorder': array([1, 2]), 'size': array([3., 1.]), 'subsize': {'hankel': array([3, 3], dtype=int64), 'other': ()}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1,2,3,4,5])\n",
    "V = hankelize(v)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01799a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (7, 1)\n",
      "Order:  4\n",
      "ind:  nan\n",
      "sizes:  [4, 3, 2]\n",
      "N:  7\n",
      "Dim:  1\n",
      "Order:  4\n",
      "ind:  [4 6 7]\n",
      "sizes:  [4, 3, 2]\n",
      "perm_to_first:  1\n",
      "size_other:  ()\n",
      "size_hankel:  [4 3 2 1]\n",
      "Total required Bytes are:  96.0\n",
      "hstruct {'type': 'hankel', 'val': array([[1],\n",
      "       [2],\n",
      "       [3],\n",
      "       [4],\n",
      "       [5],\n",
      "       [6],\n",
      "       [7]]), 'dim': 1, 'order': 4, 'ind': array([4, 6, 7]), 'ispermuted': False, 'repermorder': array([1, 2, 3, 4]), 'size': array([3., 2., 1., 1.]), 'subsize': {'hankel': array([4, 3, 2, 1]), 'other': ()}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[1],\n",
       "         [2]],\n",
       "\n",
       "        [[2],\n",
       "         [3]],\n",
       "\n",
       "        [[3],\n",
       "         [4]]],\n",
       "\n",
       "\n",
       "       [[[2],\n",
       "         [3]],\n",
       "\n",
       "        [[3],\n",
       "         [4]],\n",
       "\n",
       "        [[4],\n",
       "         [5]]],\n",
       "\n",
       "\n",
       "       [[[3],\n",
       "         [4]],\n",
       "\n",
       "        [[4],\n",
       "         [5]],\n",
       "\n",
       "        [[5],\n",
       "         [6]]],\n",
       "\n",
       "\n",
       "       [[[4],\n",
       "         [5]],\n",
       "\n",
       "        [[5],\n",
       "         [6]],\n",
       "\n",
       "        [[6],\n",
       "         [7]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "V = hankelize(v, Sizes=[4, 3, 2])\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf15cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (7, 1)\n",
      "N:  7\n",
      "Dim:  1\n",
      "Order:  3\n",
      "ind:  [3 5]\n",
      "sizes:  nan\n",
      "perm_to_first:  1\n",
      "size_other:  ()\n",
      "size_hankel:  [3 3 3]\n",
      "Total required Bytes are:  108.0\n",
      "hstruct {'type': 'hankel', 'val': array([[1],\n",
      "       [2],\n",
      "       [3],\n",
      "       [4],\n",
      "       [5],\n",
      "       [6],\n",
      "       [7]]), 'dim': 1, 'order': 3, 'ind': array([3, 5], dtype=int64), 'ispermuted': False, 'repermorder': array([1, 2, 3]), 'size': array([3., 3., 1.]), 'subsize': {'hankel': array([3, 3, 3], dtype=int64), 'other': ()}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [3, 4, 5]],\n",
       "\n",
       "       [[2, 3, 4],\n",
       "        [3, 4, 5],\n",
       "        [4, 5, 6]],\n",
       "\n",
       "       [[3, 4, 5],\n",
       "        [4, 5, 6],\n",
       "        [5, 6, 7]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "V = hankelize(v, Order=3)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae8029a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstructure(*args):\n",
    "    if len(args) == 1:\n",
    "        if isinstance(args[0], (np.ndarray, int, float)):\n",
    "            structure = 'full'\n",
    "        elif isinstance(args[0], list) or isinstance(args[0], tuple):\n",
    "            if all(isinstance(item, (int, float)) for item in args[0]):\n",
    "                if all(len(item.shape) == 2 for item in args[0]):\n",
    "                    structure = 'cpd'\n",
    "                else:\n",
    "                    structure = 'tt'\n",
    "            elif all(isinstance(item, (list, tuple)) for item in args[0]):\n",
    "                structure = 'btd'\n",
    "            elif len(args[0]) > 1 and len(args[0]) == 2 and isinstance(args[0][0], (list, tuple)) and isinstance(args[0][1], (int, float)):\n",
    "                structure = 'lmlra'\n",
    "            else:\n",
    "                raise ValueError('Unknown structure')\n",
    "        elif isinstance(args[0], dict):\n",
    "            if 'incomplete' in args[0] and args[0]['incomplete']:\n",
    "                structure = 'incomplete'\n",
    "            elif 'sparse' in args[0] and args[0]['sparse']:\n",
    "                structure = 'sparse'\n",
    "            elif 'type' in args[0]:\n",
    "                structure = args[0]['type']\n",
    "            else:\n",
    "                raise ValueError('Unknown structure')\n",
    "        else:\n",
    "            raise ValueError('Unknown structure')\n",
    "    elif len(args) == 2:\n",
    "        if isinstance(args[0], (list, tuple)) and isinstance(args[1], (int, float)):\n",
    "            structure = 'lmlra'\n",
    "        else:\n",
    "            raise ValueError('Unknown structure')\n",
    "    else:\n",
    "        raise ValueError('Unknown structure')\n",
    "    \n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a92f89e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getorder(T, S=None):\n",
    "    try:\n",
    "        structure = getstructure(T)\n",
    "        if structure == 'full':\n",
    "            return len(T.shape)\n",
    "        elif structure in ['incomplete', 'sparse']:\n",
    "            if 'size' in T:\n",
    "                return len(T['size'])\n",
    "            else:\n",
    "                raise ValueError('T has an invalid structure')\n",
    "        elif structure == 'cpd':\n",
    "            return len(T)\n",
    "        elif structure == 'lmlra':\n",
    "            if S is None:\n",
    "                return len(T[0])\n",
    "            else:\n",
    "                return len(T)\n",
    "        elif structure == 'btd':\n",
    "            return len(T[0])-1\n",
    "        elif structure == 'tt':\n",
    "            return len(T)\n",
    "        elif structure in ['hankel', 'loewner', 'segment', 'decimate']:\n",
    "            if 'size' in T:\n",
    "                return len(T['size'])\n",
    "            else:\n",
    "                raise ValueError('T has an invalid structure')\n",
    "        else:\n",
    "            raise ValueError('T has an unknown structure')\n",
    "    except getstructure.UnknownStructureError:\n",
    "        raise ValueError('T has an unknown structure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e3f67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getorder(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de8ee4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.shape:  (3, 4, 3)\n",
      "T:  [[[ 18  36  54]\n",
      "  [ 36  72 108]\n",
      "  [ 54 108 162]]\n",
      "\n",
      " [[ 18  36  54]\n",
      "  [ 36  72 108]\n",
      "  [ 54 108 162]]\n",
      "\n",
      " [[ 18  36  54]\n",
      "  [ 36  72 108]\n",
      "  [ 54 108 162]]]\n",
      "T.shape:  (3, 3, 3)\n",
      "type of indices:  <class 'numpy.ndarray'>\n",
      "T_subset indices = [1, 2, 3]:  [18 18 18]\n",
      "T_subset.shape:  (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELLPR~1\\AppData\\Local\\Temp/ipykernel_7060/1468056951.py:16: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if indices[0] == ':':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nNote: You need to replace `U1`, `U2`, ..., `UK`, `S1`, `S2`, ..., `SL` with the actual matrices or arrays that make up the BTD.\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# BLOCK-Term Decomposition (BTD) \n",
    "# BTDGEN Generate full tensor given a BTD.\n",
    "def btdgen(U, *indices):\n",
    "    N = len(U[0]) - 1\n",
    "    size_tens = [np.size(U[0][n], 0) for n in range(N)]\n",
    "    if len(indices) == 0:\n",
    "        T = U[0][0] @ np.kron(U[0][-1].T, [U[0][n] for n in range(N)]) \n",
    "        #T = np.resize(T, size_tens)\n",
    "        for r in range(1, len(U)):\n",
    "            T = T + U[r][0] @ np.kron(U[r][-1].T, [U[r][n] for n in range(N)])\n",
    "        T = np.resize(T, size_tens)\n",
    "        return T\n",
    "    \n",
    "    elif len(indices) == 1:\n",
    "        if indices[0] == ':':\n",
    "            T = btdgen(U).flatten()\n",
    "            return T\n",
    "        \n",
    "        size_output = np.shape(indices[0])\n",
    "        T = 0        \n",
    "        if indices[0].ndim == 1:  # Linear indexing\n",
    "            sub = np.unravel_index(indices[0], size_tens)\n",
    "        else:\n",
    "            sub = indices[0]\n",
    "\n",
    "        sub = np.array(sub)\n",
    "        sub = sub.astype(np.int64)\n",
    "\n",
    "        for r in range(len(U)):\n",
    "            S = U[r][N]\n",
    "            size_core = [np.size(U[r][n]) for n in range(len(U[r]) - 1)]\n",
    "            idx = np.zeros((1, len(U[r])-1), dtype=np.int64) \n",
    "            idx = idx.squeeze()\n",
    "            for i in range(np.size(S)):\n",
    "                tmp = np.dot (S[idx[i]] , U[r][0][sub[0][idx[0]]])\n",
    "                for n in range(1, len(size_core)):\n",
    "                    tmp =  np.dot(tmp , U[r][n][sub[n][ idx[n]]])\n",
    "                \n",
    "                T = T + tmp\n",
    "        \n",
    "        return np.resize(T, size_output)\n",
    "    \n",
    "    elif len(indices) == N + 1:\n",
    "        for r in range(len(U)):\n",
    "            for n in range(N):\n",
    "                U[r][n] = U[r][n][np.ix_(indices[n])]\n",
    "        \n",
    "        return btdgen(U)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Either linear or subscripts indices should be provided\")\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "You can use this function by passing the BTD tensor `U` and the desired indices as arguments. For example:\n",
    "\n",
    "'''\n",
    "U1 = [1, 2, 3]\n",
    "U2 = [1, 2, 3]\n",
    "U3 = [1, 2, 3]\n",
    "S1 = [1, 2, 3]\n",
    "S2 = [1, 2, 3]\n",
    "S3 = [1, 2, 3]\n",
    "\n",
    "U = [[U1, U2, U3, S1],\n",
    "     [U1, U2, U3, S2],\n",
    "     [U1, U2, U3, S3]]\n",
    "U = np.array(U)\n",
    "print (\"U.shape: \", U.shape)\n",
    "T = btdgen(U)  # Compute the full tensor T\n",
    "print (\"T: \",T)\n",
    "print (\"T.shape: \",T.shape)\n",
    "indices = np.array([1, 2, 3])\n",
    "indices = indices.astype(np.int64)\n",
    "print (\"type of indices: \", type(indices))\n",
    "T_subset = btdgen(U, indices)  # Compute a subset of the tensor T\n",
    "print (\"T_subset indices = [1, 2, 3]: \",T_subset)\n",
    "print (\"T_subset.shape: \",T_subset.shape)\n",
    "'''\n",
    "\n",
    "Note: You need to replace `U1`, `U2`, ..., `UK`, `S1`, `S2`, ..., `SL` with the actual matrices or arrays that make up the BTD.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f46e2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def ful(T, *args):\n",
    "    type = getstructure(T)\n",
    "    if type == 'full':\n",
    "        if len(args) > 0:\n",
    "            T = T[args]\n",
    "    elif type == 'cpd':\n",
    "        T = cpdgen(T, *args)\n",
    "    elif type == 'lmlra':\n",
    "        T = lmlragen(T[0], T[1], *args)\n",
    "    elif type == 'btd':\n",
    "        T = btdgen(T, *args)\n",
    "    elif type == 'tt':\n",
    "        T = ttgen(T, *args)\n",
    "    elif type == 'hankel':\n",
    "        if len(args) == 0:\n",
    "            H = hankelize(T.val, dim=1, order=T.order, ind=T.ind, full=True, perm=True, fullLimit=np.inf)\n",
    "            H = np.reshape(H, [T.subsize.hankel, T.subsize.other])\n",
    "            T = permute(H, T.repermorder)\n",
    "        elif len(args) == 1:\n",
    "            if args[0] == ':':\n",
    "                T = np.reshape(ful(T), [-1, 1])\n",
    "                return T\n",
    "            sub = []\n",
    "            for i in range(getorder(T)):\n",
    "                sub.append(np.unravel_index(args[0], getsize(T)[i]))\n",
    "        elif len(args) == getorder(T) + 1:\n",
    "            for i in range(len(args)):\n",
    "                if args[i] == ':':\n",
    "                    args[i] = np.arange(1, T.size[i] + 1)\n",
    "            sub = np.meshgrid(*args, indexing='ij')\n",
    "            sub = [np.ravel(x) for x in sub]\n",
    "        else:\n",
    "            raise ValueError('Either linear or subscripts indices should be provided')\n",
    "        \n",
    "        if len(args) > 0:\n",
    "            otherdims = list(range(1, T.dim)) + list(range(T.dim + T.order, getorder(T)))\n",
    "            dims = list(range(T.dim, T.dim + T.order))\n",
    "            dataind = np.sum(np.stack(sub)[dims], axis=0) - T.order + 1\n",
    "            if len(otherdims) == 0:\n",
    "                dataotherind = np.ones_like(dataind)\n",
    "            elif len(otherdims) == 1:\n",
    "                dataotherind = sub[otherdims[0]]\n",
    "            else:\n",
    "                dataotherind = np.ravel_multi_index(sub[otherdims], T.subsize.other)\n",
    "            \n",
    "            valind = np.ravel_multi_index([dataind, dataotherind], T.val.shape)\n",
    "            \n",
    "            if len(args) == 2:\n",
    "                T = np.reshape(T.val[valind], args[0].shape)\n",
    "            else:\n",
    "                shape = [len(arg) for arg in args]\n",
    "                T = np.reshape(T.val[valind], shape)\n",
    "            \n",
    "    elif type == 'loewner':\n",
    "        if len(args) == 0:\n",
    "            L = loewnerize(T.val, dim=1, order=T.order, ind=T.ind, full=True, perm=True, t=T.t, fullLimit=np.inf)\n",
    "            L = np.reshape(L, [T.subsize.loewner, T.subsize.other])\n",
    "            T = permute(L, T.repermorder)\n",
    "        elif len(args) == 1:\n",
    "            if args[0] == ':':\n",
    "                T = np.reshape(ful(T), [-1, 1])\n",
    "                return T\n",
    "            sub = []\n",
    "            for i in range(getorder(T)):\n",
    "                sub.append(np.unravel_index(args[0], getsize(T)[i]))\n",
    "        elif len(args) == getorder(T) + 1:\n",
    "            for i in range(len(args)):\n",
    "                if args[i] == ':':\n",
    "                    args[i] = np.arange(1, T.size[i] + 1)\n",
    "            sub = np.meshgrid(*args, indexing='ij')\n",
    "            sub = [np.ravel(x) for x in sub]\n",
    "        else:\n",
    "            raise ValueError('Either linear or subscripts indices should be provided')\n",
    "        \n",
    "        if len(args) > 0:\n",
    "            otherdims = list(range(1, T.dim)) + list(range(T.dim + T.order, getorder(T)))\n",
    "            dims = list(range(T.dim, T.dim + T.order))\n",
    "            \n",
    "            if len(otherdims) == 1:\n",
    "                dataotherind = sub[otherdims[0]]\n",
    "            elif len(otherdims) > 1:\n",
    "                dataotherind = np.ravel_multi_index(sub[otherdims], T.subsize.other)\n",
    "            \n",
    "            totaldata = 0\n",
    "            for i in range(len(dims)):\n",
    "                idx = T.ind[i][sub[dims[i]]].T\n",
    "                \n",
    "                if len(otherdims) == 0:\n",
    "                    linidx = idx\n",
    "                else:\n",
    "                    linidx = np.ravel_multi_index([idx, dataotherind], T.val.shape)\n",
    "                \n",
    "                data = T.val[linidx]\n",
    "                for o in list(range(1, i)) + list(range(i + 1, len(dims))):\n",
    "                    data = data / (T.t[T.ind[i][sub[dims[i]]]] - T.t[T.ind[o][sub[dims[o]]]])\n",
    "                \n",
    "                totaldata = totaldata + data\n",
    "            \n",
    "            if len(args) == 2:\n",
    "                T = np.reshape(totaldata, args[0].shape)\n",
    "            else:\n",
    "                shape = [len(arg) for arg in args]\n",
    "                T = np.reshape(totaldata, shape)\n",
    "    \n",
    "    elif type in ['incomplete', 'sparse']:\n",
    "        val = T.val\n",
    "        size_tens = T.size\n",
    "        \n",
    "        if len(args) == 0:\n",
    "            if 8 * np.prod(size_tens) > 8e9:\n",
    "                raise ValueError('T is too large to be stored as an array.')\n",
    "            if not hasattr(T, 'ind'):\n",
    "                ind = np.ravel_multi_index(T.sub, size_tens)\n",
    "            else:\n",
    "                ind = T.ind\n",
    "            \n",
    "            if type == 'sparse':\n",
    "                T = coo_matrix((val, (ind, np.zeros_like(ind))), shape=size_tens).toarray()\n",
    "            else:\n",
    "                T = np.full(size_tens, np.nan)\n",
    "                T[ind] = val\n",
    "        elif len(args) == 1:\n",
    "            if args[0] == ':':\n",
    "                T = np.reshape(ful(T), [-1, 1])\n",
    "                return T\n",
    "            if not hasattr(T, 'ind'):\n",
    "                T = fmt(T)\n",
    "            if type == 'incomplete':\n",
    "                val = np.full(args[0].shape, np.nan)\n",
    "            else:\n",
    "                val = np.zeros(args[0].shape)\n",
    "            ia, ib = np.isin(args[0], T.ind)\n",
    "            val[ia] = T.val[ib[ia]]\n",
    "            T = val\n",
    "        elif len(args) == len(size_tens) + 1:\n",
    "            size_result = [len(arg) for arg in args]\n",
    "            if 8 * np.prod(size_result) > 8e9:\n",
    "                raise ValueError('T is too large to be stored as an array.')\n",
    "            if not hasattr(T, 'ind'):\n",
    "                T = fmt(T)\n",
    "            if type == 'incomplete':\n",
    "                val = np.full(size_result, np.nan)\n",
    "            else:\n",
    "                val = np.zeros(size_result)\n",
    "            sub = np.meshgrid(*args, indexing='ij')\n",
    "            ind = np.ravel_multi_index(sub, T.size)\n",
    "            ia, ib = np.isin(ind, T.ind)\n",
    "            val[ia] = T.val[ib[ia]]\n",
    "            T = val\n",
    "        else:\n",
    "            raise ValueError('Either linear or subscripts indices should be provided')\n",
    "    \n",
    "    elif type == 'segment':\n",
    "        X = desegmentize(T)\n",
    "        X = segmentize(X, dim=T.dim, order=T.order, segsize=T.segsize, perm=T.ispermuted, shift=T.shift)\n",
    "        T = ful(X, *args)\n",
    "    \n",
    "    elif type == 'decimate':\n",
    "        X = dedecimate(T)\n",
    "        X = decimate(X, dim=T.dim, order=T.order, subsample=T.subsample, perm=T.ispermuted, shift=T.shift)\n",
    "        T = ful(X, *args)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Unknown structured tensor type.')\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "513c0f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.fftpack as fft\n",
    "import itertools\n",
    "# This function attempts to write in Python the similar function in Tensorlab Matlab toolbox\n",
    "# I kept only some options working, and others attempted without testing, and others not attempted at all\n",
    "\n",
    "def dehankelize(H, **kwargs):\n",
    "    def hankel_freq(order, size_hankel, N):\n",
    "        # Construct the frequencies of the data - it seems not correct\n",
    "        if order == 2:\n",
    "            m = min(size_hankel[0], N-size_hankel[0]+1)\n",
    "            w = np.concatenate((np.arange(1, m), m*np.ones(N-2*m+2), np.arange(m-1, 0, -1)))\n",
    "            w = w.reshape(-1, 1) # transpose\n",
    "        else:\n",
    "            w = np.fft.fft(np.ones(size_hankel[0]), N)\n",
    "            if w.shape[0] == 1:\n",
    "                w = w.reshape(1, -1)\n",
    "            for i in range(1, len(size_hankel)):\n",
    "                tmp = np.fft.fft(np.ones(size_hankel[i]), N)\n",
    "                if tmp.shape[0] == 1:\n",
    "                    w = w * tmp.reshape(1, -1)\n",
    "                else:\n",
    "                    w = w * tmp\n",
    "            w = np.round(np.fft.ifft(w)).astype(int)\n",
    "    \n",
    "        return w\n",
    "\n",
    "    def sub_hankel(sizes):\n",
    "        # Construct the indices of the Hankel matrix/tensor\n",
    "        allind = np.arange(1, sizes[0] + 1)\n",
    "        for i in range(1, len(sizes)):\n",
    "            ridx = np.arange(sizes[i])\n",
    "            ridx = np.reshape(ridx, [1] * i + [len(ridx)])\n",
    "            lidx = np.add.outer(allind, ridx)\n",
    "            allind = lidx.flatten()\n",
    "\n",
    "        return allind\n",
    "    \n",
    "    defaultKwargs = { 'Order': 2,\n",
    "        'Dim': 1,\n",
    "        'Dims': np.NaN,\n",
    "        'Method':'mean',\n",
    "        'PermToDim': np.NaN,\n",
    "        'Rank':  np.NaN\n",
    "        }\n",
    "    order = kwargs.get('Order', 2)\n",
    "    dim = kwargs.get('Dim', 1)\n",
    "    dims = kwargs.get('Dims', np.NaN)\n",
    "    method = kwargs.get('Method', 'mean')\n",
    "    permToDim = kwargs.get('PermToDim', np.NaN)\n",
    "    rank = kwargs.get('Rank', np.NaN)\n",
    "    \n",
    "    args = {'Order': order,\n",
    "        'Dim': dim,\n",
    "        'Dims': dims,\n",
    "        'Method': method,\n",
    "        'PermToDim': permToDim,\n",
    "        'Rank': rank}\n",
    "    KeepUnmatched = False\n",
    "    isdefault =  args ==defaultKwargs\n",
    "    shared_items = {k: args[k] for k in args if k in defaultKwargs and args[k] == defaultKwargs[k]}\n",
    "    \n",
    "    if not np.isnan(dims):\n",
    "        if dim != 1: # not default and set by caller\n",
    "            raise ValueError('Using both the ''Dim'' and ''Dims'' option arguments is invalid!')  \n",
    "        if order != 2: # not default, set by caller\n",
    "            if dims+order-1>getorder(H):\n",
    "                raise ValueError('The given order is not consistent with the dimensions of H!')\n",
    "            if len(dims)==1:\n",
    "                dims = np.arange(dims[0],dims[0]+order)\n",
    "        else: # order is not set\n",
    "            if np.any(dims>getorder(H)):\n",
    "                raise ValueError('The given dehankelization dimensions are not consistent with the dimensions of H!')\n",
    "            order = len(dims)\n",
    "        if len(dims!=order):\n",
    "            raise ValueError('The number of detensorized dimensions should be equal to the order!');\n",
    "    else: # dims is not set by the caller\n",
    "        if dim != 1: # not default and set by caller\n",
    "            if dim+order-1>getorder(H):\n",
    "                raise ValueError('The given dehankelization dimensions are not consistent with the dimensions of H!')        \n",
    "        if order != 2 and order>getorder(H):\n",
    "            raise ValueError('The given order is not consistent with the dimensions of H!')\n",
    "        dims = np.arange(dim,(dim+order))\n",
    "    if getstructure(H)!='cpd' and not np.isnan(rank):\n",
    "        raise ValueError('The rank option is not supported when H is not a CPD!')\n",
    "    dims=np.array(dims)\n",
    "    np.reshape(dims, np.hstack((1, dims.shape)))\n",
    "    \n",
    "    #Dehankelization\n",
    "    H_str = getstructure(H)        \n",
    "    if H_str == 'full':\n",
    "        # Given a full tensor\n",
    "        sh = np.shape(H)\n",
    "        print (\"sh: \", sh)\n",
    "        print (\"dims: \", dims)\n",
    "        size_hankel = [sh[i-1] for i in dims]\n",
    "        if method == 'fibers':\n",
    "            subs = np.tile(Ellipsis, (H.ndim))\n",
    "            #subs =   [Ellipsis, Ellipsis]\n",
    "            #subs(dims(2:end)) = {1}\n",
    "            print (\"subs : \", subs)\n",
    "            for i in range(1, len(subs)):\n",
    "                subs[i] = 0\n",
    "            #for i in range(1, len(dims)):\n",
    "            #    subs[dims[i]-1] = 0\n",
    "            #X = np.zeros((order,1))\n",
    "            X = []\n",
    "            print (\"subs : \", subs)\n",
    "            for i in range(order):\n",
    "                if i != 0:\n",
    "                    subs[dims[i-1]-1] = np.array(sh[dims[i-1]]-1)\n",
    "                    subs[dims[i]-1] =np.hstack(range(1, sh[dims[i]-1]))           \n",
    "                print (\"subs : \", subs)\n",
    "                print (\"H : \", H)\n",
    "                tmp = H[list(subs)]\n",
    "                sizes = np.squeeze(np.hstack((np.shape(tmp) , np.squeeze( np.ones ( (1, np.ndim(H) - np.ndim(tmp)))))))\n",
    "                sizes = sizes.astype(np.int64)\n",
    "                perm_vec = list(range(H.ndim))\n",
    "                xx = perm_vec[0] \n",
    "                perm_vec[0] = perm_vec[dims[i]-1]\n",
    "                perm_vec[dims[i]-1] = xx\n",
    "                if len(tmp.shape) < len(perm_vec):\n",
    "                    tmp = np.reshape(tmp, np.hstack((tmp.shape, 1)))\n",
    "                elif len(perm_vec) < len(tmp.shape):\n",
    "                     perm_vec = np.reshape(perm_vec, np.hstack((perm_vec.shape, 1)))\n",
    "                tmp = np.transpose(tmp, tuple(perm_vec))\n",
    "                print (\"perm_vec: \", perm_vec)\n",
    "                print (\"tmp: \", tmp)\n",
    "                sizes = [sizes[j] for j in perm_vec]\n",
    "                #sizes = tuple([sizes[j] for j in perm_vec if j in dims[:i] or j in dims[i+2:]])\n",
    "                x = list(sizes)\n",
    "                for j in range (i+1, len(dims)):\n",
    "                    x.pop(perm_vec[dims[j]-1])\n",
    "                sizes = np.array(x)\n",
    "                if len(sizes)==1:\n",
    "                    sizes.resize ((2))\n",
    "                    sizes[1] = 1\n",
    "                print (\"sizes after resize: \", sizes)\n",
    "                if np.ndim(tmp) != 0:\n",
    "                    tmp = np.resize(tmp, sizes)\n",
    "                else:\n",
    "                    tmp = np.asarray([])\n",
    "                tmp = tmp.squeeze()\n",
    "                X.append(tmp)\n",
    "            signaldim = int(dims[0] - np.sum([dims[d] for d in range(1, len(dims)) if dims[0] > dims[d]]))\n",
    "            X = np.concatenate(X, axis=signaldim-1)\n",
    "            #X = np.array(X)\n",
    "            \n",
    "        else: # Use another technique than fibres\n",
    "            H_mat = np.reshape(H, [-1, size_hankel[-1]]) # tensor to matrix\n",
    "            ind_f = np.cumsum(size_hankel) - np.arange(order)\n",
    "            N = ind_f[-1]\n",
    "            w = hankel_freq(order, size_hankel, N)\n",
    "            sample_ind = sub_hankel(size_hankel)\n",
    "            if method == 'mean':\n",
    "                # Extract means by performing a two-step procedure to\n",
    "                # improve accuracy\n",
    "                # first step is to dehankelize by fibers and PermtoDim 1\n",
    "                options_quick = defaultKwargs.copy()\n",
    "                options_quick['PermToDim'] = 1\n",
    "                options_quick['Method'] = 'fibers'\n",
    "                x_estimate = dehankelize(H, **options_quick)\n",
    "                \n",
    "                # The following second step computes the frequenct and compute the means to subtract\n",
    "                # from the estimated matrix. The Python functions are different from Matlab\n",
    "                # I did not complete testing this part to finalise it, so result can be returned with the \n",
    "                # current estimated accuracy.\n",
    "                '''\n",
    "                #x_estimate = np.reshape(x_estimate, [-1, size_hankel[-1]]) # tensor to matrix\n",
    "                x_estimate =  np.array(x_estimate)\n",
    "                if x_estimate.ndim==1:\n",
    "                        x_estimate.resize ((x_estimate.shape[0], 1))\n",
    "                for k in range(np.size(H_mat, 1)):\n",
    "                    #diff = H_mat[:, k] - x_estimate[sample_ind-1][0]\n",
    "                    # tmp = accumarray(sampleind,diff,[],@sum)./w;\n",
    "                    tmp = np.bincount(sample_ind)/w #, weights=diff) / w\n",
    "                    x_estimate[:][k] = x_estimate[:][k] + tmp\n",
    "                    '''\n",
    "                X = x_estimate\n",
    "            else: # Extract something else than means (such as median)\n",
    "                x_estimate = np.empty((N, np.size(H_mat)))\n",
    "                for k in range(np.size(H_mat)):\n",
    "                    # xestimate(:,k) = accumarray(sampleind,Hmat(:,k),[],method);\n",
    "                    # we need a numpy function to accumulate the values given the function in the Method option\n",
    "                    # left to future work, and just using mean again \n",
    "                    x_estimate[:][k] = np.bincount(sample_ind, weights=Hmat[:][k]) / w\n",
    "                X = x_estimate\n",
    "            sx = sh \n",
    "            sx = np.array(sx).astype(float)  # because Nan is float, will convert here\n",
    "            sx[dims-1] = np.NaN\n",
    "            sx[dims[0]] = N\n",
    "            sx = sx[np.logical_not(np.isnan(sx))] # remove all Nans\n",
    "            sx = np.array(sx).astype(int) # return to int to use as index \n",
    "            signaldim = int(dims[0] - np.sum([dims[d] for d in range(1, len(dims)) if dims[0] > dims[d]]))\n",
    "            X = np.resize(x_estimate, [sx[signaldim-1]]) # mat2tens(xestimate,sx,signaldim);\n",
    "              \n",
    "               \n",
    "    elif H_str == 'hankel': # Given an efficient (block-)Hankel representation\n",
    "        print (\"Future work\")\n",
    "    elif H_str == 'cpd': # Given a representation of a tensor in rank-1 terms\n",
    "        print (\"Future work\")    \n",
    "    elif H_str in {'incomplete','sparse','tt','btd','lmlragen'}:\n",
    "        T = ful(H)\n",
    "        X = dehankelize(T,**kwargs)\n",
    "    else:\n",
    "        raise ValueError('Structure not supported!')\n",
    "    \n",
    "    # Permute the data to specific dimensions\n",
    "    if not np.isnan(permToDim):\n",
    "        permToDim = int(permToDim)\n",
    "        signaldim = int(signaldim)\n",
    "        if signaldim < permToDim:\n",
    "            permvec = list(range(0, signaldim)) + list(range(signaldim+1, permToDim)) + [signaldim] + list(range(permToDim+1, np.ndim(X)))\n",
    "        else:\n",
    "            permvec = list(range(0, permToDim)) + [signaldim] + list(range(permToDim, signaldim)) + list(range(signaldim+1, np.ndim(X)))\n",
    "        if X.ndim==1:\n",
    "            X.resize ((X.shape[0], 1))\n",
    "        X = np.squeeze(np.transpose(X, permvec))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62fd568f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (7, 1)\n",
      "Order:  2\n",
      "ind:  [4]\n",
      "N:  7\n",
      "Dim:  1\n",
      "Order:  2\n",
      "ind:  [4]\n",
      "sizes:  nan\n",
      "perm_to_first:  1\n",
      "size_other:  ()\n",
      "size_hankel:  [4 4]\n",
      "Total required Bytes are:  64.0\n",
      "hstruct {'type': 'hankel', 'val': array([[1],\n",
      "       [2],\n",
      "       [3],\n",
      "       [4],\n",
      "       [5],\n",
      "       [6],\n",
      "       [7]]), 'dim': 1, 'order': 2, 'ind': array([4], dtype=int64), 'ispermuted': False, 'repermorder': array([1, 2]), 'size': array([4., 1.]), 'subsize': {'hankel': array([4, 4], dtype=int64), 'other': ()}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [2, 3, 4, 5],\n",
       "       [3, 4, 5, 6],\n",
       "       [4, 5, 6, 7]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1,2,3,4,5, 6, 7])\n",
    "H = hankelize(v)\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "660ecb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [2, 3, 4, 5],\n",
       "       [3, 4, 5, 6],\n",
       "       [4, 5, 6, 7]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = ful(H)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58e8f2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh:  (4, 4)\n",
      "dims:  [1 2]\n",
      "sh:  (4, 4)\n",
      "dims:  [1 2]\n",
      "subs :  [Ellipsis Ellipsis]\n",
      "subs :  [Ellipsis 0]\n",
      "subs :  [Ellipsis 0]\n",
      "H :  [[1 2 3 4]\n",
      " [2 3 4 5]\n",
      " [3 4 5 6]\n",
      " [4 5 6 7]]\n",
      "perm_vec:  [0, 1]\n",
      "tmp:  [[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "sizes after resize:  [4 1]\n",
      "subs :  [array(3) array([1, 2, 3])]\n",
      "H :  [[1 2 3 4]\n",
      " [2 3 4 5]\n",
      " [3 4 5 6]\n",
      " [4 5 6 7]]\n",
      "perm_vec:  [1, 0]\n",
      "tmp:  [[5 6 7]]\n",
      "sizes after resize:  [1 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELLPR~1\\AppData\\Local\\Temp/ipykernel_7060/1455814808.py:115: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  tmp = H[list(subs)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = dehankelize(H)\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af69471",
   "metadata": {},
   "source": [
    "##### BSS Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86048eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (101, 3)\n",
      "Order:  2\n",
      "ind:  [51]\n",
      "N:  101\n",
      "Dim:  1\n",
      "Order:  2\n",
      "ind:  [51]\n",
      "sizes:  nan\n",
      "perm_to_first:  1\n",
      "size_other:  (3,)\n",
      "size_hankel:  [51 51]\n",
      "Total required Bytes are:  62424.0\n",
      "hstruct {'type': 'hankel', 'val': array([[ -0.80860177,  -0.40420054,   2.67434975],\n",
      "       [ -0.82774144,  -0.4333433 ,   2.75965358],\n",
      "       [ -0.84748753,  -0.46394025,   2.84805242],\n",
      "       [ -0.86786308,  -0.49605743,   2.93966248],\n",
      "       [ -0.88889206,  -0.52976379,   3.0346044 ],\n",
      "       [ -0.91059942,  -0.56513123,   3.13300339],\n",
      "       [ -0.93301115,  -0.60223483,   3.23498943],\n",
      "       [ -0.95615432,  -0.64115293,   3.34069745],\n",
      "       [ -0.98005708,  -0.68196725,   3.4502675 ],\n",
      "       [ -1.00474878,  -0.72476308,   3.56384497],\n",
      "       [ -1.03025997,  -0.76962942,   3.6815808 ],\n",
      "       [ -1.05662245,  -0.81665913,   3.80363167],\n",
      "       [ -1.08386936,  -0.86594907,   3.93016022],\n",
      "       [ -1.11203518,  -0.91760032,   4.0613353 ],\n",
      "       [ -1.14115584,  -0.97171834,   4.19733221],\n",
      "       [ -1.17126876,  -1.02841312,   4.33833292],\n",
      "       [ -1.20241291,  -1.08779943,   4.48452635],\n",
      "       [ -1.23462888,  -1.14999699,   4.63610865],\n",
      "       [ -1.26795893,  -1.21513067,   4.79328342],\n",
      "       [ -1.30244709,  -1.28333075,   4.95626209],\n",
      "       [ -1.33813923,  -1.35473311,   5.12526412],\n",
      "       [ -1.3750831 ,  -1.42947948,   5.30051741],\n",
      "       [ -1.41332848,  -1.50771769,   5.48225852],\n",
      "       [ -1.45292718,  -1.58960193,   5.67073311],\n",
      "       [ -1.49393319,  -1.675293  ,   5.86619621],\n",
      "       [ -1.53640275,  -1.76495863,   6.06891263],\n",
      "       [ -1.58039445,  -1.85877374,   6.2791573 ],\n",
      "       [ -1.62596931,  -1.95692074,   6.49721572],\n",
      "       [ -1.67319092,  -2.05958987,   6.72338429],\n",
      "       [ -1.72212549,  -2.16697952,   6.9579708 ],\n",
      "       [ -1.77284203,  -2.27929657,   7.20129483],\n",
      "       [ -1.82541242,  -2.39675674,   7.45368823],\n",
      "       [ -1.87991154,  -2.519585  ,   7.71549557],\n",
      "       [ -1.93641741,  -2.64801592,   7.98707466],\n",
      "       [ -1.99501131,  -2.78229408,   8.26879706],\n",
      "       [ -2.05577791,  -2.92267451,   8.56104858],\n",
      "       [ -2.11880543,  -3.06942312,   8.86422987],\n",
      "       [ -2.1841858 ,  -3.22281717,   9.17875699],\n",
      "       [ -2.25201477,  -3.38314572,   9.50506198],\n",
      "       [ -2.32239212,  -3.55071013,   9.84359353],\n",
      "       [ -2.39542179,  -3.72582463,  10.19481756],\n",
      "       [ -2.4712121 ,  -3.90881679,  10.55921795],\n",
      "       [ -2.54987589,  -4.10002813,  10.93729721],\n",
      "       [ -2.63153073,  -4.29981465,  11.32957722],\n",
      "       [ -2.71629913,  -4.50854753,  11.73659994],\n",
      "       [ -2.80430871,  -4.72661368,  12.15892825],\n",
      "       [ -2.89569247,  -4.95441643,  12.59714673],\n",
      "       [ -2.99058896,  -5.19237624,  13.05186251],\n",
      "       [ -3.08914257,  -5.44093139,  13.52370613],\n",
      "       [ -3.19150371,  -5.70053874,  14.01333252],\n",
      "       [ -3.29782913,  -5.97167451,  14.52142184],\n",
      "       [ -3.40828214,  -6.25483509,  15.04868057],\n",
      "       [ -3.5230329 ,  -6.55053786,  15.59584246],\n",
      "       [ -3.64225871,  -6.85932212,  16.16366966],\n",
      "       [ -3.7661443 ,  -7.18174997,  16.75295374],\n",
      "       [ -3.89488218,  -7.51840728,  17.36451694],\n",
      "       [ -4.02867289,  -7.86990466,  17.99921329],\n",
      "       [ -4.16772543,  -8.23687853,  18.65792988],\n",
      "       [ -4.31225755,  -8.61999218,  19.34158815],\n",
      "       [ -4.46249612,  -9.0199369 ,  20.05114524],\n",
      "       [ -4.61867756,  -9.43743314,  20.78759536],\n",
      "       [ -4.78104819,  -9.87323173,  21.55197129],\n",
      "       [ -4.94986466, -10.32811517,  22.3453458 ],\n",
      "       [ -5.12539443, -10.80289893,  23.16883333],\n",
      "       [ -5.30791612, -11.29843283,  24.02359151],\n",
      "       [ -5.49772009, -11.81560249,  24.91082293],\n",
      "       [ -5.69510886, -12.35533079,  25.83177686],\n",
      "       [ -5.90039765, -12.91857946,  26.78775109],\n",
      "       [ -6.11391489, -13.50635071,  27.78009383],\n",
      "       [ -6.33600281, -14.11968885,  28.81020569],\n",
      "       [ -6.56701798, -14.75968212,  29.87954173],\n",
      "       [ -6.80733193, -15.42746449,  30.98961358],\n",
      "       [ -7.05733178, -16.12421755,  32.14199171],\n",
      "       [ -7.31742089, -16.85117254,  33.33830766],\n",
      "       [ -7.58801951, -17.60961237,  34.58025653],\n",
      "       [ -7.86956553, -18.40087379,  35.86959938],\n",
      "       [ -8.16251522, -19.22634965,  37.20816591],\n",
      "       [ -8.46734396, -20.0874912 ,  38.59785707],\n",
      "       [ -8.78454705, -20.98581055,  40.04064794],\n",
      "       [ -9.11464059, -21.92288318,  41.5385906 ],\n",
      "       [ -9.45816227, -22.90035062,  43.09381715],\n",
      "       [ -9.81567235, -23.91992312,  44.70854288],\n",
      "       [-10.18775455, -24.98338259,  46.38506955],\n",
      "       [-10.57501707, -26.09258552,  48.12578875],\n",
      "       [-10.97809359, -27.24946611,  49.93318551],\n",
      "       [-11.39764431, -28.45603949,  51.80984188],\n",
      "       [-11.83435713, -29.71440509,  53.75844084],\n",
      "       [-12.28894873, -31.02675013,  55.78177023],\n",
      "       [-12.76216584, -32.39535327,  57.88272691],\n",
      "       [-13.25478643, -33.82258842,  60.06432101],\n",
      "       [-13.76762106, -35.31092867,  62.32968047],\n",
      "       [-14.30151424, -36.86295044,  64.6820556 ],\n",
      "       [-14.8573458 , -38.48133774,  67.12482398],\n",
      "       [-15.43603243, -40.16888664,  69.66149546],\n",
      "       [-16.03852916, -41.92850993,  72.29571735],\n",
      "       [-16.66583101, -43.76324195,  75.03127989],\n",
      "       [-17.31897463, -45.67624366,  77.87212187],\n",
      "       [-17.99904001, -47.67080782,  80.82233653],\n",
      "       [-18.70715236, -49.75036456,  83.88617759],\n",
      "       [-19.44448391, -51.91848697,  87.06806569],\n",
      "       [-20.21225596, -54.17889709,  90.37259492]]), 'dim': 1, 'order': 2, 'ind': array([51], dtype=int64), 'ispermuted': False, 'repermorder': array([1, 2, 3]), 'size': array([51.,  3.,  1.]), 'subsize': {'hankel': array([51, 51], dtype=int64), 'other': (3,)}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-4.82883465, -0.01759559,  1.39157075,  0.        ],\n",
       "        [-4.8273387 , -0.01759559,  1.44324595,  0.4372869 ],\n",
       "        [-4.82808008, -0.01759559,  1.49788044,  0.01401496],\n",
       "        [-4.82808008, -0.01759559,  1.54782743,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  1.60328124,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  1.65996398,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  1.71850038,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  1.77886318,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  1.84118121,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  1.90554539,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  1.97206365,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.04076207,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.11172233,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.18502702,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.26075529,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.33970524,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.42132369,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.50563252,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.59274868,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.68277024,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.77579817,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.87193713,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.97129542,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.07398522,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.18012272,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.28982825,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.40322644,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.52044642,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.6416219 ,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  3.67960013,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  6.68428186,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.92509481,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.92509481,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.92509481,  0.        ],\n",
       "        [-4.82808008, -0.01759559,  2.92509481,  0.        ]]),\n",
       " array([[-0.00115392,  0.06980825,  0.07678347,  0.02365198],\n",
       "        [-0.00115392,  0.07584889,  0.09584068,  0.27306038],\n",
       "        [-0.00115392,  0.07808   ,  0.09757075,  0.14835323],\n",
       "        [-0.00115392,  0.08153606,  0.10005763,  0.14835277],\n",
       "        [-0.00115392,  0.08517305,  0.10339262,  0.14341901],\n",
       "        [-0.00115392,  0.08861107,  0.10592297,  0.10438296],\n",
       "        [-0.00115392,  0.0922471 ,  0.10862693,  0.06798447],\n",
       "        [-0.00115392,  0.09608897,  0.1115103 ,  0.03427256],\n",
       "        [-0.00115392,  0.10037972,  0.11494238,  0.01374604],\n",
       "        [-0.00115392,  0.10578807,  0.11918333,  0.01374597],\n",
       "        [-0.00115392,  0.11215645,  0.12317354,  0.01373209],\n",
       "        [-0.00115392,  0.12015438,  0.12734899,  0.01369178],\n",
       "        [-0.00115392,  0.12856111,  0.13168689,  0.01364889],\n",
       "        [-0.00115392,  0.1370418 ,  0.13618238,  0.01361227],\n",
       "        [-0.00115392,  0.14557642,  0.14084093,  0.01361227],\n",
       "        [-0.00115392,  0.15378063,  0.14569578,  0.01361227],\n",
       "        [-0.00115392,  0.16169533,  0.15106457,  0.01361227],\n",
       "        [-0.00115392,  0.16978426,  0.15671227,  0.01361227],\n",
       "        [-0.00115392,  0.17817448,  0.16260093,  0.01361227],\n",
       "        [-0.00115392,  0.18693085,  0.16871982,  0.01361227],\n",
       "        [-0.00115392,  0.19606908,  0.1750781 ,  0.01361227],\n",
       "        [-0.00115392,  0.20560554,  0.18168528,  0.01361227],\n",
       "        [-0.00115392,  0.2155573 ,  0.18855129,  0.01361227],\n",
       "        [-0.00115392,  0.22594216,  0.19568643,  0.01361227],\n",
       "        [-0.00115392,  0.23672221,  0.20312235,  0.01361227],\n",
       "        [-0.00115392,  0.24781852,  0.21090685,  0.01361227],\n",
       "        [-0.00115392,  0.25939637,  0.2189975 ,  0.01361227],\n",
       "        [-0.00115392,  0.27147635,  0.22740651,  0.01361227],\n",
       "        [-0.00115392,  0.28407989,  0.2361466 ,  0.01361227],\n",
       "        [-0.00115392,  0.29722935,  0.24523097,  0.01361227],\n",
       "        [-0.00115392,  0.31094804,  0.25467339,  0.01361227],\n",
       "        [-0.00115392,  0.32526024,  0.26448815,  0.01361227],\n",
       "        [-0.00115392,  0.34019124,  0.27469012,  0.01361227],\n",
       "        [-0.00115392,  0.35576743,  0.28529478,  0.01361227],\n",
       "        [-0.00115392,  0.37201629,  0.29631823,  0.01361227],\n",
       "        [-0.00115392,  0.38826043,  0.29913643,  0.01361227],\n",
       "        [-0.00115392,  0.40436439,  0.29913643,  0.01351149],\n",
       "        [-0.00115392,  0.42168584,  0.29913643,  0.01329527],\n",
       "        [-0.00115392,  0.44142636,  0.29913643,  0.01301685],\n",
       "        [-0.00115392,  0.46385729,  0.29913643,  0.01270179],\n",
       "        [-0.00115392,  0.48734298,  0.29913643,  0.01236441],\n",
       "        [-0.00115392,  0.51196487,  0.29913643,  0.01200646],\n",
       "        [-0.00115392,  0.51395489,  0.29913643,  0.01163861],\n",
       "        [-0.00115392,  0.51395489,  0.29913643,  0.01140009],\n",
       "        [-0.00115392,  0.51395489,  0.29913643,  0.01102611],\n",
       "        [-0.00115392,  0.51395489,  0.29913643,  0.01072638],\n",
       "        [-0.00115392,  0.51395489,  0.29913643,  0.01067082],\n",
       "        [-0.00115392,  0.51395489,  0.29913643,  0.01063203],\n",
       "        [-0.00115392,  0.51395489,  0.47637092,  0.01055735],\n",
       "        [-0.00115392,  0.74820731,  0.2102415 ,  0.00523118],\n",
       "        [-0.00115392,  0.27952928,  0.2102415 ,  0.        ]]),\n",
       " array([[  0.        ,  28.40074645,  -6.9261291 ,   5.48435728],\n",
       "        [  0.        , 781.66502197,   6.43143961,  11.93377662],\n",
       "        [837.15777244,   0.        ,   6.43143961,   0.        ]])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# application BSS Signal construction\n",
    "t = np.linspace(0,1,101).T\n",
    "x = np.array([t, t*2, t*3, t*4]).T\n",
    "S = np.exp(x)\n",
    "rng = np.random.default_rng()\n",
    "M = rng.standard_normal(size=(4,3)) # generate random mixing matrix\n",
    "X = np.dot(S,M)\n",
    "# Separation\n",
    "H = hankelize(X,Dim=1)\n",
    "U = tl.tensor(H)\n",
    "\n",
    "from tensorly.decomposition import constrained_parafac\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rank = 4\n",
    "_, factors = constrained_parafac(U, rank=rank, unimodality=True)\n",
    "factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8dae6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELLPR~1\\AppData\\Local\\Temp/ipykernel_7060/4075969018.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  factors = np.array(factors)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors = np.array(factors)\n",
    "factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deb7b411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 51, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = np.stack((factors[0], factors[1]))\n",
    "t1.shape\n",
    "#t1 = t1.reshape((len(t1[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e71ce656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELLPR~1\\AppData\\Local\\Temp/ipykernel_7060/1455814808.py:115: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  tmp = H[list(subs)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh:  (2, 51, 4)\n",
      "dims:  [1 2]\n",
      "sh:  (2, 51, 4)\n",
      "dims:  [1 2]\n",
      "subs :  [Ellipsis Ellipsis Ellipsis]\n",
      "subs :  [Ellipsis 0 0]\n",
      "subs :  [Ellipsis 0 0]\n",
      "H :  [[[-4.82883465e+00 -1.75955855e-02  1.39157075e+00  0.00000000e+00]\n",
      "  [-4.82733870e+00 -1.75955855e-02  1.44324595e+00  4.37286900e-01]\n",
      "  [-4.82808008e+00 -1.75955855e-02  1.49788044e+00  1.40149615e-02]\n",
      "  [-4.82808008e+00 -1.75955855e-02  1.54782743e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  1.60328124e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  1.65996398e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  1.71850038e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  1.77886318e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  1.84118121e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  1.90554539e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  1.97206365e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.04076207e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.11172233e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.18502702e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.26075529e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.33970524e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.42132369e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.50563252e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.59274868e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.68277024e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.77579817e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.87193713e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.97129542e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.07398522e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.18012272e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.28982825e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.40322644e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.52044642e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.64162190e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  3.67960013e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  6.68428186e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.92509481e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.92509481e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.92509481e+00  0.00000000e+00]\n",
      "  [-4.82808008e+00 -1.75955855e-02  2.92509481e+00  0.00000000e+00]]\n",
      "\n",
      " [[-1.15391611e-03  6.98082493e-02  7.67834680e-02  2.36519833e-02]\n",
      "  [-1.15391611e-03  7.58488899e-02  9.58406827e-02  2.73060382e-01]\n",
      "  [-1.15391611e-03  7.80799994e-02  9.75707519e-02  1.48353228e-01]\n",
      "  [-1.15391611e-03  8.15360630e-02  1.00057634e-01  1.48352766e-01]\n",
      "  [-1.15391611e-03  8.51730485e-02  1.03392621e-01  1.43419012e-01]\n",
      "  [-1.15391611e-03  8.86110715e-02  1.05922971e-01  1.04382965e-01]\n",
      "  [-1.15391611e-03  9.22470985e-02  1.08626926e-01  6.79844708e-02]\n",
      "  [-1.15391611e-03  9.60889720e-02  1.11510305e-01  3.42725621e-02]\n",
      "  [-1.15391611e-03  1.00379720e-01  1.14942385e-01  1.37460397e-02]\n",
      "  [-1.15391611e-03  1.05788074e-01  1.19183327e-01  1.37459661e-02]\n",
      "  [-1.15391611e-03  1.12156446e-01  1.23173540e-01  1.37320869e-02]\n",
      "  [-1.15391611e-03  1.20154382e-01  1.27348988e-01  1.36917812e-02]\n",
      "  [-1.15391611e-03  1.28561108e-01  1.31686895e-01  1.36488865e-02]\n",
      "  [-1.15391611e-03  1.37041799e-01  1.36182380e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  1.45576424e-01  1.40840934e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  1.53780628e-01  1.45695781e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  1.61695328e-01  1.51064573e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  1.69784258e-01  1.56712266e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  1.78174476e-01  1.62600929e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  1.86930845e-01  1.68719819e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  1.96069076e-01  1.75078096e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  2.05605537e-01  1.81685283e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  2.15557303e-01  1.88551291e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  2.25942164e-01  1.95686426e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  2.36722214e-01  2.03122354e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  2.47818524e-01  2.10906851e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  2.59396375e-01  2.18997499e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  2.71476346e-01  2.27406512e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  2.84079887e-01  2.36146598e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  2.97229353e-01  2.45230974e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  3.10948042e-01  2.54673390e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  3.25260235e-01  2.64488145e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  3.40191240e-01  2.74690117e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  3.55767430e-01  2.85294778e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  3.72016290e-01  2.96318226e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  3.88260432e-01  2.99136431e-01  1.36122708e-02]\n",
      "  [-1.15391611e-03  4.04364393e-01  2.99136431e-01  1.35114909e-02]\n",
      "  [-1.15391611e-03  4.21685841e-01  2.99136431e-01  1.32952672e-02]\n",
      "  [-1.15391611e-03  4.41426356e-01  2.99136431e-01  1.30168542e-02]\n",
      "  [-1.15391611e-03  4.63857294e-01  2.99136431e-01  1.27017880e-02]\n",
      "  [-1.15391611e-03  4.87342982e-01  2.99136431e-01  1.23644133e-02]\n",
      "  [-1.15391611e-03  5.11964868e-01  2.99136431e-01  1.20064580e-02]\n",
      "  [-1.15391611e-03  5.13954893e-01  2.99136431e-01  1.16386143e-02]\n",
      "  [-1.15391611e-03  5.13954893e-01  2.99136431e-01  1.14000879e-02]\n",
      "  [-1.15391611e-03  5.13954893e-01  2.99136431e-01  1.10261148e-02]\n",
      "  [-1.15391611e-03  5.13954893e-01  2.99136431e-01  1.07263779e-02]\n",
      "  [-1.15391611e-03  5.13954893e-01  2.99136431e-01  1.06708209e-02]\n",
      "  [-1.15391611e-03  5.13954893e-01  2.99136431e-01  1.06320259e-02]\n",
      "  [-1.15391611e-03  5.13954893e-01  4.76370916e-01  1.05573522e-02]\n",
      "  [-1.15391611e-03  7.48207309e-01  2.10241502e-01  5.23117535e-03]\n",
      "  [-1.15391611e-03  2.79529277e-01  2.10241502e-01  0.00000000e+00]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DELLPR~1\\AppData\\Local\\Temp/ipykernel_7060/2164073681.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdehankelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# ,'L'=[1, 1, 1, 1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mSest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\DELLPR~1\\AppData\\Local\\Temp/ipykernel_7060/1455814808.py\u001b[0m in \u001b[0;36mdehankelize\u001b[1;34m(H, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0moptions_quick\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PermToDim'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[0moptions_quick\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Method'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'fibers'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                 \u001b[0mx_estimate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdehankelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions_quick\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;31m# The following second step computes the frequenct and compute the means to subtract\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\DELLPR~1\\AppData\\Local\\Temp/ipykernel_7060/1455814808.py\u001b[0m in \u001b[0;36mdehankelize\u001b[1;34m(H, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm_vec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                      \u001b[0mperm_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                 \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"perm_vec: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"tmp: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \"\"\"\n\u001b[1;32m--> 660\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'transpose'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "Sest = dehankelize(t1) # ,'L'=[1, 1, 1, 1])\n",
    "Sest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42992358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Ellipsis, Ellipsis, Ellipsis], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = np.tile(Ellipsis, (H.ndim))\n",
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "90ba8ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "ab34e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(subs)):\n",
    "    subs[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "b52003d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Ellipsis, 0, 0], dtype=object)"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "29c018fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DELLPR~1\\AppData\\Local\\Temp/ipykernel_19408/3711530430.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Sest' is not defined"
     ]
    }
   ],
   "source": [
    "Sest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "c790bed2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DELLPR~1\\AppData\\Local\\Temp/ipykernel_19408/2920492207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Error calculation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mRMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sest' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# yet to pythonise\n",
    "\n",
    "# Error calculation\n",
    "MSE = np.square(np.subtract(S,Sest)).mean() \n",
    " \n",
    "RMSE = math.sqrt(MSE)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "U = cpd(H,4);\n",
    "Sest = dehankelize(U(1:2),'L',[1 1 1 1]);\n",
    "% Error calculation\n",
    "cpderr(S,Sest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
